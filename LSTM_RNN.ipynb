{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--vHyYAZdV6U"
   },
   "source": [
    "# LSTM RNN\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRK1uedMi7q_"
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from plotting import Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting global variables\n",
    "tickers = ['ARKK','SPY','FNGU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in ETF data to DataFrame\n",
    "etf_data = pd.read_csv(Path('./Resources/Data/etf_data.csv'), index_col='Date', parse_dates=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating ETF DataFrame into separate DataFrames\n",
    "arkk,spy,fngu = [etf_data[i].to_frame(i) for i in tickers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda helper methods\n",
    "get_scaler = lambda df: MinMaxScaler(feature_range=(0,1)).fit(df)\n",
    "get_scaled = lambda scaler, array: scaler.transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jGHfpjIvhn0",
    "outputId": "73715f95-8c42-4315-eea3-060be0414ff4"
   },
   "outputs": [],
   "source": [
    "# Creating scalers and Numpy arrays\n",
    "arkk_scaler, spy_scaler, fngu_scaler =  get_scaler(arkk),get_scaler(spy),get_scaler(fngu)\n",
    "arkk_array, spy_array, fngu_array = [i.values for i in [arkk,spy,fngu]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created scaled data\n",
    "arkk_scaled, spy_scaled, fngu_scaled = [get_scaled(i[0],i[1]) for i in [(arkk_scaler,arkk_array),(spy_scaler,spy_array),(fngu_scaler,fngu_array)]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting forecasting timeframe (60 days) and training length\n",
    "forecast_length = 60\n",
    "training_length = len(etf_data) - forecast_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAReFKlyxSdV",
    "outputId": "d31a6e14-d802-40d8-d7d6-5ec42e22cc9a"
   },
   "outputs": [],
   "source": [
    "# Method for train test split\n",
    "def train_test_split(scaled_data, array):\n",
    "    # Creating features and targets\n",
    "    X, y = scaled_data[0:training_length, :], scaled_data[training_length - forecast_length:, :]\n",
    "\n",
    "    # Intializing training and testing variables\n",
    "    X_train, X_test, y_train = [],[],[]\n",
    "\n",
    "    # Looping from forecast_length to end of features\n",
    "    for i in range(forecast_length, len(X)):\n",
    "        # Appending training data\n",
    "        X_train.append(X[i-forecast_length:i, 0])\n",
    "        y_train.append(X[i,0])\n",
    "\n",
    "    # Loopiung from forecast_length to end of features\n",
    "    for i in range(forecast_length, len(y)):\n",
    "        # Appending testing data\n",
    "        X_test.append(y[i-forecast_length:i, 0])\n",
    "    # Converting data to Numpy Array    \n",
    "    X_train, X_test, y_train = np.array(X_train), np.array(X_test), np.array(y_train)\n",
    "    # Reshaping testing data array\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Returning training and testing features and targets\n",
    "    return [X_train, X_test, y_train, array[training_length:, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gChz0Omt_5Xb"
   },
   "outputs": [],
   "source": [
    "# Splitting scaled data into train and test features and targets\n",
    "arkk_X_train, arkk_X_test, arkk_y_train, arkk_y_test =  train_test_split(arkk_scaled, arkk_array)\n",
    "spy_X_train, spy_X_test, spy_y_train, spy_y_test = train_test_split(spy_scaled, spy_array)\n",
    "fngu_X_train, fngu_X_test, fngu_y_train, fngu_y_test = train_test_split(fngu_scaled, fngu_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to create, summarize and compile model\n",
    "def get_model():\n",
    "    # Creating Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Adding LSTM layer to model\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(forecast_length, 1)))\n",
    "    # Adding LSTM layer to model\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    # Adding Dense layer to model\n",
    "    model.add(Dense(25))\n",
    "    # Adding output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Displaying model summary\n",
    "    display(model.summary())\n",
    "    \n",
    "    # Compiling model\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mse'])\n",
    "    \n",
    "    # Returning model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nIgdv2cMK1ej"
   },
   "outputs": [],
   "source": [
    "# Creating models\n",
    "arkk_model, spy_model, fngu_model = [get_model() for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Size and Epochs variables for model training\n",
    "batch_size,epochs = 1,35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZA2EuB6zMIbi",
    "outputId": "add8f863-51cc-4082-f564-215ac9628ae5"
   },
   "outputs": [],
   "source": [
    "# Training ARKK Model\n",
    "arkk_model.fit(arkk_X_train, arkk_y_train, batch_size=batch_size, epochs=epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training SPY Model\n",
    "spy_model.fit(spy_X_train, spy_y_train, batch_size=batch_size, epochs=epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training FNGU Model\n",
    "fngu_model.fit(fngu_X_train, fngu_y_train, batch_size=batch_size, epochs=epochs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHRweClsPWp5",
    "outputId": "5cce878f-ac99-4744-afd4-2a1ca885f3f8"
   },
   "outputs": [],
   "source": [
    "# Forecasting with ARKK Model\n",
    "arkk_forecast = arkk_model.predict(arkk_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting with SPY Model\n",
    "spy_forecast = spy_model.predict(spy_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting with FNGU Model\n",
    "fngu_forecast = fngu_model.predict(fngu_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print evaluation metrics\n",
    "def evaluate(ticker, model, scaler, forecast, y_test):\n",
    "    # Saving evaluation metrics\n",
    "    metrics = model.evaluate(forecast,y_test)\n",
    "    \n",
    "    # Printing ETF ticker\n",
    "    print(ticker)\n",
    "    \n",
    "    # Saving each metric as variable\n",
    "    mae,mse,rmse = round(metrics[0],2),round(metrics[1],2),round(metrics[1]**.5,2)\n",
    "    # Printing metrics\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Root Mean Squared Error: {rmse}')\n",
    "    \n",
    "    # Returning metrics\n",
    "    return [mae,mse,rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARKK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and printing ARKK metrics\n",
    "arkk_mae, arkk_mse, arkk_rmse = evaluate(tickers[0], arkk_model, arkk_scaler, arkk_forecast, arkk_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and printing SPY metrics\n",
    "spy_mae, spy_mse, spy_rmse = evaluate(tickers[1], spy_model, spy_scaler, spy_forecast, spy_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and printing FNGU metrics\n",
    "fngu_mae, fngu_mse, fngu_rmse = evaluate(tickers[2], fngu_model, fngu_scaler, fngu_forecast, fngu_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda helper method to create DataFrame of error metrics\n",
    "get_error_df = lambda a,s,f: pd.DataFrame({tickers[0]:a,tickers[1]:s,tickers[2]:f}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating custom plotter class\n",
    "plotter = Plotter('LSTM_RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MAS bar plot\n",
    "plotter.bar(get_error_df(arkk_mae,spy_mae,fngu_mae),'Mean Absolute Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MSE bar plot\n",
    "plotter.bar(get_error_df(arkk_mse,spy_mse,fngu_mse),'Mean Squared Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting RMSE bar plot\n",
    "plotter.bar(get_error_df(arkk_rmse,spy_rmse,fngu_rmse),'Root Mean Squared Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Actual vs Forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to display DataFrame head and tail\n",
    "display_head_tail = lambda df: display(df.head(),df.tail())\n",
    "# Variable for titles\n",
    "avf = 'Actual vs Forecasted'\n",
    "# Helper method to get titles\n",
    "get_avf_title = lambda index: tickers[index] + ' ' + avf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to get actual and forecasted adjusted closing prices as DataFrame\n",
    "def get_actual_forecasted(df, forecast, scaler): \n",
    "    # Getting ticker symbol\n",
    "    ticker = df.columns[0]\n",
    "    # Creating dataframe from testing DataFrame\n",
    "    actual_forecasted = df[training_length:]\n",
    "    \n",
    "    # Renaming actual column\n",
    "    actual_forecasted.rename(columns={ticker:f'{ticker} Actual Adjusted Close'}, inplace=True)\n",
    "    \n",
    "    # Setting forecasted column\n",
    "    actual_forecasted[f'{ticker} Forecasted Adjusted Close'] = scaler.inverse_transform(forecast)\n",
    "    # Rounding forecasted column\n",
    "    actual_forecasted[f'{ticker} Forecasted Adjusted Close'] = actual_forecasted[f'{ticker} Forecasted Adjusted Close'].apply(lambda x: round(x,2))\n",
    "    \n",
    "    # Returning actual and forecasted values as DataFrame\n",
    "    return actual_forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying ARKK actual and forecasted adjusted closing prices\n",
    "arkk_actual_forecasted = get_actual_forecasted(arkk,arkk_forecast,arkk_scaler)\n",
    "display_head_tail(arkk_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ARKK actual vs forecasted adjusted closing prices\n",
    "plotter.line(arkk_actual_forecasted, get_avf_title(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying SPY actual and forecasted adjusted closing prices\n",
    "spy_actual_forecasted = get_actual_forecasted(spy,spy_forecast,spy_scaler)\n",
    "display_head_tail(spy_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting SPY actual vs forecasted adjusted closing prices\n",
    "plotter.line(spy_actual_forecasted, get_avf_title(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying FNGU actual and forecasted adjusted closing prices\n",
    "fngu_actual_forecasted = get_actual_forecasted(fngu,fngu_forecast,fngu_scaler)\n",
    "display_head_tail(fngu_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FNGU actual vs forecasted adjusted closing prices\n",
    "plotter.line(fngu_actual_forecasted, get_avf_title(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying ETF actual and forecasted adjusted closing prices\n",
    "actual_forecasted = pd.concat([arkk_actual_forecasted,spy_actual_forecasted,fngu_actual_forecasted], axis=1, join='inner')\n",
    "display_head_tail(actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ETF actual vs forecasted adjusted closing prices\n",
    "plotter.line(actual_forecasted, avf, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting heatmap of actual ETF price correlation\n",
    "actual = pd.concat([arkk_actual_forecasted.iloc[:,0],spy_actual_forecasted.iloc[:,0],fngu_actual_forecasted.iloc[:,0]], join='inner', axis=1)\n",
    "plotter.heatmap(actual, 'Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting heatmap of forecasted ETF price correlation\n",
    "forecasted = pd.concat([arkk_actual_forecasted.iloc[:,1],spy_actual_forecasted.iloc[:,1],fngu_actual_forecasted.iloc[:,1]], join='inner', axis=1)\n",
    "plotter.heatmap(forecasted, 'Forecasted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting heatmap of actual vs forecasted ETF price correlation\n",
    "plotter.heatmap(actual_forecasted, avf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data vs Actual vs Forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame of training, actual and forecasted adjusted cloding prices\n",
    "training_data = etf_data[:training_length].rename(columns={tickers[i]: tickers[i] + ' Training Data' for i in range(3)})\n",
    "train_actual_forecasted = pd.concat([training_data,actual_forecasted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to get DataFrame by ticker\n",
    "get_df_by_ticker = lambda ticker: train_actual_forecasted[[col for col in train_actual_forecasted if col.startswith(ticker)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for title and lambda helper method to get title\n",
    "taf = 'Training Data vs Actual vs Forecasted'\n",
    "get_train_title = lambda index: tickers[index] + ' ' + taf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying ARKK data\n",
    "arrk_train_actual_forecasted = get_df_by_ticker(tickers[0])\n",
    "display_head_tail(arrk_train_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ARKK data\n",
    "plotter.line(arrk_train_actual_forecasted, get_train_title(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying SPY data\n",
    "spy_train_actual_forecasted = get_df_by_ticker(tickers[1])\n",
    "display_head_tail(spy_train_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting SPY data\n",
    "plotter.line(spy_train_actual_forecasted, get_train_title(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and displaying FNGU data\n",
    "fngu_train_actual_forecasted = get_df_by_ticker(tickers[2])\n",
    "display_head_tail(fngu_train_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting FNGU data\n",
    "plotter.line(fngu_train_actual_forecasted, get_train_title(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying ETF data\n",
    "display_head_tail(train_actual_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ETF data\n",
    "plotter.line(train_actual_forecasted, taf, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ETF training data heatmap\n",
    "plotter.heatmap(etf_data[:training_length], 'Training Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
